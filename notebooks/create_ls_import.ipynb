{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1 True\n",
      "2.25.2\n",
      "10.2\n",
      "GCC 7.3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(mmdet.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/erik/Riksarkivet/Projects/lagfarter/data/file_names_lagfarter_det_2.json', 'r') as f:\n",
    "    export = json.load(f)\n",
    "\n",
    "df_lagf = pd.read_csv('/home/erik/Riksarkivet/Projects/lagfarter/data/db_files/Uttag_Lagfartsbok_2022-09-14', sep='\\t', encoding='utf8', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /home/erik/Riksarkivet/Projects/lagfarter/models/det_crcnn_iter_2_2500/latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/Riksarkivet/Projects/lagfarter/mmdetection/mmdet/datasets/utils.py:70: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "\n",
    "import_list = []\n",
    "\n",
    "#img = mmcv.imread('/home/erik/Riksarkivet/Projects/lagfarter/data/det_set_import_2/51/SE_HLA1340060_CIa_4_000377.jpg')\n",
    "\n",
    "cfg = Config.fromfile('/home/erik/Riksarkivet/Projects/lagfarter/models/configs/cascade_rcnn2.py')\n",
    "\n",
    "checkpoint = '/home/erik/Riksarkivet/Projects/lagfarter/models/det_crcnn_iter_2_2500/latest.pth'\n",
    "model = init_detector(cfg, checkpoint, device='cuda:0')\n",
    "\n",
    "imgs = glob('/home/erik/Riksarkivet/Projects/lagfarter/data/det_set_import_2/**/*.jpg', recursive=True)\n",
    "\n",
    "imgs = [x for x in imgs if int(x.split('/')[-2]) not in range(49,52)]\n",
    "\n",
    "imgs.sort()\n",
    "\n",
    "for i, inst in enumerate(export):\n",
    "    \n",
    "    img_p = [x for x in imgs if x.split('/')[-1] == inst['file_upload'].split('-')[1]]\n",
    "    \n",
    "    if len(img_p) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        img_p = img_p[0]\n",
    "\n",
    "    try:\n",
    "        arkis_nr = inst['data']['image'].split('-')[1].split('_')[1]\n",
    "        series = inst['data']['image'].split('-')[1].split('_')[2]\n",
    "        volume = inst['data']['image'].split('-')[1].split('_')[3]\n",
    "        page_nr = str(int(inst['data']['image'].split('-')[1].split('_')[4].split('.')[0]))\n",
    "        row = df_lagf[(df_lagf['ARKISNR'] == arkis_nr) & (df_lagf['ARKISSIG'] == series) & (df_lagf['ARKISVOL'] == volume) & (df_lagf['APAGE'] == page_nr)]\n",
    "        \n",
    "        gt = str(row.iloc[0]['SOCKEN']) + ';' + str(row.iloc[0]['FAST']) + ';' + str(row.iloc[0]['FASTNR1'])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    image_dict = dict()\n",
    "    image_dict['data'] = inst['data']\n",
    "    image_dict['predictions'] = list()\n",
    "    image_dict['predictions'].append(dict())\n",
    "    image_dict['predictions'][0]['result'] = list()\n",
    "    image_dict['predictions'][0]['result'].append(dict())\n",
    "    image_dict['predictions'][0]['result'][0]['value'] = dict()\n",
    "    image_dict['predictions'][0]['result'][0]['value']['text'] = list()\n",
    "    image_dict['predictions'][0]['result'][0]['value']['text'].append(gt)\n",
    "    image_dict['predictions'][0]['result'][0]['from_name'] = 'transcription'\n",
    "    image_dict['predictions'][0]['result'][0]['to_name'] = 'image'\n",
    "    image_dict['predictions'][0]['result'][0]['type'] = 'textarea'\n",
    "    \n",
    "    img = mmcv.imread(img_p)\n",
    "    result = result = inference_detector(model, img)\n",
    "\n",
    "    for j, cat in enumerate(result):\n",
    "        \n",
    "        id_pred = 'result' + str(j)\n",
    "        category = ''\n",
    "        \n",
    "        if j == 0:\n",
    "            category = 'Pagenr'\n",
    "        elif j == 1:\n",
    "            category = 'Property'\n",
    "        elif j == 2:\n",
    "            category = 'Propnr'\n",
    "        elif j == 3:\n",
    "            category = 'Socken'\n",
    "\n",
    "        if len(cat) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            max_cat = max(cat, key=lambda x: x[4])\n",
    "            \n",
    "            x = float(max_cat[0] / img.shape[1] * 100)\n",
    "            y = float(max_cat[1] / img.shape[0] * 100)\n",
    "\n",
    "            width = float((max_cat[2] - max_cat[0]) / img.shape[1] * 100)\n",
    "            height = float((max_cat[3] - max_cat[1]) / img.shape[0] * 100)\n",
    "            \n",
    "            #image_dict['predictions'].append(dict())\n",
    "            #image_dict['predictions'][-1]['model_version'] = 'one'\n",
    "            #image_dict['predictions'][-1]['score'] = float(max_cat[4])\n",
    "            #image_dict['predictions'][-1]['result'] = list()\n",
    "            image_dict['predictions'][0]['result'].append(dict())\n",
    "            image_dict['predictions'][0]['result'][-1]['id'] = id_pred\n",
    "            image_dict['predictions'][0]['result'][-1]['type'] = 'rectanglelabels'\n",
    "            image_dict['predictions'][0]['result'][-1]['from_name'] = 'label'\n",
    "            image_dict['predictions'][0]['result'][-1]['to_name'] = 'image'\n",
    "            image_dict['predictions'][0]['result'][-1]['original_width'] = float(img.shape[1])\n",
    "            image_dict['predictions'][0]['result'][-1]['original_height'] = float(img.shape[0])\n",
    "            image_dict['predictions'][0]['result'][-1]['image_rotation'] = 0\n",
    "            image_dict['predictions'][0]['result'][-1]['value'] = dict()\n",
    "            image_dict['predictions'][0]['result'][-1]['value']['rotation'] = 0\n",
    "            image_dict['predictions'][0]['result'][-1]['value']['x'] = x\n",
    "            image_dict['predictions'][0]['result'][-1]['value']['y'] = y\n",
    "            image_dict['predictions'][0]['result'][-1]['value']['width'] = width\n",
    "            image_dict['predictions'][0]['result'][-1]['value']['height'] = height\n",
    "            image_dict['predictions'][0]['result'][-1]['value']['rectanglelabels'] = [category]\n",
    "\n",
    "    import_list.append(image_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_list = []\n",
    "\n",
    "for i, inst in enumerate(export):\n",
    "    \n",
    "\n",
    "    arkis_nr = inst['data']['image'].split('-')[1].split('_')[1]\n",
    "    series = inst['data']['image'].split('-')[1].split('_')[2]\n",
    "    volume = inst['data']['image'].split('-')[1].split('_')[3]\n",
    "    page_nr = str(int(inst['data']['image'].split('-')[1].split('_')[4].split('.')[0]))\n",
    "    row = df_lagf[(df_lagf['ARKISNR'] == arkis_nr) & (df_lagf['ARKISSIG'] == series) & (df_lagf['ARKISVOL'] == volume) & (df_lagf['APAGE'] == page_nr)]\n",
    "    #print(i)\n",
    "    try:\n",
    "        gt = str(row.iloc[0]['SOCKEN']) + ';' + str(row.iloc[0]['FAST']) + ';' + str(row.iloc[0]['FASTNR1'])\n",
    "    except:\n",
    "        print('error')\n",
    "        continue\n",
    "\n",
    "    image_dict = dict()\n",
    "    image_dict['data'] = inst['data']\n",
    "    image_dict['predictions'] = list()\n",
    "    image_dict['predictions'].append(dict())\n",
    "    image_dict['predictions'][0]['result'] = list()\n",
    "    image_dict['predictions'][0]['result'].append(dict())\n",
    "    image_dict['predictions'][0]['result'][0]['value'] = dict()\n",
    "    image_dict['predictions'][0]['result'][0]['value']['text'] = list()\n",
    "    image_dict['predictions'][0]['result'][0]['value']['text'].append(gt)\n",
    "    image_dict['predictions'][0]['result'][0]['from_name'] = 'transcription'\n",
    "    image_dict['predictions'][0]['result'][0]['to_name'] = 'image'\n",
    "    image_dict['predictions'][0]['result'][0]['type'] = 'textarea'\n",
    "\n",
    "    import_list.append(image_dict)\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/erik/Riksarkivet/Projects/lagfarter/output/ls_import_3_with_preds.json', 'w') as f:\n",
    "    json.dump(import_list, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('lagfarter': conda)",
   "name": "python3713jvsc74a57bd01c548d5a8b3d4454c9603ca2a0dc189d675989076af75dc267ab6735625d4f70"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}